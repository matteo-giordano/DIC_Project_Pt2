algorithm: TabularQLearningAgent                    # name of the agent class to use
map: ../datachallengeg15/grid_configs/A1_grid.npy   # path to the map to use
start_cell: [11, 3]                                 # starting cell of the agent on map
max_episodes: 10_000                                # maximum number of episodes to run
max_steps: 10_000                                   # maximum number of steps to run
early_stopping_threshold: 200                       # number of episodes to run before stopping the training
reward_fn: reward_fn                                # name of the reward function to use
max_workers: 11                                     # number of cores to run in parallel
n_trials: 500                                         # number of trials to run for each combination of algorithm parameters
n_seeds: 10                                          # number of seeds to run for each combination of algorithm parameters
sigma: [0, 0.9, 20]                                  # [min, max, number of trials] to run for each sigma for each seed & algorithm parameters
# total number of trials = n_trials * n_seeds * n_sigma

algorithm_params:
    # for each parameter, provide the min, max of the range to be searched
    "alpha": [0.01, 0.99]               # QL
    "epsilon": [0.01, 0.99]             # QL, MC 
    #"epsilon_decay": [0.6, 0.999]      # MC
    #"epsilon_min": [0.001, 0.3]        # MC




