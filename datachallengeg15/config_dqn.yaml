seed: 42
model_path: "dqn_maze_model.pth"

agent:
  state_dim: 11
  action_dim: 8
  hidden_size: 128
  learning_rate: 0.001
  gamma: 0.99
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay_steps: 500
  batch_size: 64
  memory_size: 10000
  target_update_freq: 10

reward:
  name: RewardFunction
  args:
    success_reward: 100.0
    step_penalty: 0.001
    distance_penalty_coef: 0.1
    loop_penalty: 1
    loop_threshold: 0.2
    min_history_for_loop: 3

trainer:
  episodes: 1500
  max_steps: 250
  update_frequency: 5
  enable_live_tracking: true
  test_episodes: 10

env:
  map_path: "datachallengeg15/warehouse.npy"
  name: Environment
  step_size: 0.4
  goals: [[15.8, 37], [17, 18], [5, 6], [2, 35]]
  start_pos: [15.8, 37]